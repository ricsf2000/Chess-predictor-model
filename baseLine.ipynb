{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd613f03",
   "metadata": {},
   "source": [
    "## Getting a Baseline\n",
    "\n",
    "\n",
    "In order to determine a baseline for our chess predictor model we first have to define some prediction objectives. For instance we have to figure out the game outcome (win/loss/draw).\n",
    "What is the next best move, move classification such as blunder, mistake, good, and excellent.\n",
    "\n",
    "So first what we will do is look at the features of the data and select only the material_balance, and the result_class.\n",
    "\n",
    "This is so we can predict who will win base on the material balance of the chess pieces on the board as well as getting the result of the match to compare the model to.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b46aba78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the first dictionary: dict_keys(['result', 'result_class', 'white_elo', 'black_elo', 'elo_diff', 'eco', 'time_control', 'base_time_seconds', 'increment_seconds', 'time_class', 'moves', 'legal_moves_count', 'white_material', 'black_material', 'material_balance', 'white_can_castle', 'black_can_castle', 'white_center_control', 'black_center_control'])\n",
      "result: type=<class 'str'>, value=1-0\n",
      "result_class: type=<class 'int'>, value=0\n",
      "white_elo: type=<class 'int'>, value=1247\n",
      "black_elo: type=<class 'int'>, value=1218\n",
      "elo_diff: type=<class 'int'>, value=29\n",
      "eco: type=<class 'str'>, value=C25\n",
      "time_control: type=<class 'str'>, value=180+0\n",
      "base_time_seconds: type=<class 'int'>, value=180\n",
      "increment_seconds: type=<class 'int'>, value=0\n",
      "time_class: type=<class 'str'>, value=blitz\n",
      "moves: type=<class 'list'>, value=['b1c3', 'e7e5', 'e2e4', 'f8c5', 'd1h5', 'g8f6', 'h5e5', 'c5e7', 'd2d3', 'd7d6', 'e5f4', 'f6h5', 'f4f3', 'h5f6', 'f3g3', 'f6g4', 'f1e2', 'h7h5', 'e2g4', 'c8g4', 'f2f3', 'h5h4', 'g3g4', 'g7g6', 'c3d5', 'e7f8', 'c1g5', 'd8d7', 'd5f6']\n",
      "legal_moves_count: type=<class 'list'>, value=[20, 20, 22, 29, 31, 30, 42, 3, 44, 23, 44, 32, 40, 33, 38, 32, 37, 35, 38, 31, 35, 34, 35, 27, 39, 25, 43, 24, 47]\n",
      "white_material: type=<class 'int'>, value=36\n",
      "black_material: type=<class 'int'>, value=32\n",
      "material_balance: type=<class 'int'>, value=4\n",
      "white_can_castle: type=<class 'bool'>, value=True\n",
      "black_can_castle: type=<class 'bool'>, value=True\n",
      "white_center_control: type=<class 'int'>, value=2\n",
      "black_center_control: type=<class 'int'>, value=1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"lichess_processed_1000000_games_first_15_moves.pkl\"\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Examine the first dictionary\n",
    "first_item = data[0]\n",
    "print(\"Keys in the first dictionary:\", first_item.keys())\n",
    "\n",
    "# Print the type and shape of each value\n",
    "for key, value in first_item.items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"{key}: type={type(value)}, shape={value.shape}, dtype={value.dtype}\")\n",
    "    else:\n",
    "        print(f\"{key}: type={type(value)}, value={value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c502b",
   "metadata": {},
   "source": [
    "## Making the model\n",
    "\n",
    "After we see what kind of data we're using we then filter out the data that we actually need which is material_balance and result_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d27dd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Ensure data is a list of dicts with required keys\n",
    "filtered_data = [\n",
    "    item for item in data\n",
    "    if isinstance(item, dict) and 'material_balance' in item and 'result_class' in item\n",
    "]\n",
    "\n",
    "X = np.array([item['material_balance'] for item in filtered_data]).reshape(-1, 1)\n",
    "y = np.array([item['result_class'] for item in filtered_data])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b0d2c",
   "metadata": {},
   "source": [
    "Here I decided to use a MLP because we're only dealing with a singular, simple numeric feature. Where as if I was creating a model based on all  of the features of the data\n",
    "then I might go with something like a CNN or a RNN because of the spatial data and the sequential  data that the dataset provides.\n",
    "\n",
    "\n",
    "Furthermore, I standardize the features of the material_balance mainly because it allows for more stable training which is essential for getting accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6807c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc1dbab",
   "metadata": {},
   "source": [
    "Here is where I defined the MLP and used forward pass for the input. As you can see we only have 3 output layers which correspond with results of the chess match \"White wins, Black wins, or Draw\"\n",
    "\n",
    "I also chose 32, and 16 mainly because it gave me the most balance when creating the MLP, of course I could change it to find the best hyperparameter. \n",
    "But for creating a baseline I figured that a simple model would work best in this situation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3fa8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 3)  # 3 output classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bad2ac6",
   "metadata": {},
   "source": [
    "I chose 50 epochs here because we aren't trying to get the best accuracy or loss here yet. That's for later on, but 50 epochs is a good baseline to start off with to see how well our model performs.\n",
    "As you can see the loss isn't that great for the model, but it is decreasing  slowly which means that if we train for more epochs we should be able to get an accurate model.\n",
    "\n",
    "Or by introducing  more features or better balance we should be able to create a model that accurately predicts a chess game in the first 15 moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00fc9f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Loss: 1.1386\n",
      "Epoch 10/50 - Loss: 1.1092\n",
      "Epoch 15/50 - Loss: 1.0812\n",
      "Epoch 20/50 - Loss: 1.0537\n",
      "Epoch 25/50 - Loss: 1.0266\n",
      "Epoch 30/50 - Loss: 0.9984\n",
      "Epoch 35/50 - Loss: 0.9694\n",
      "Epoch 40/50 - Loss: 0.9405\n",
      "Epoch 45/50 - Loss: 0.9137\n",
      "Epoch 50/50 - Loss: 0.8898\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    logits = model(X_train_tensor)\n",
    "    loss = loss_fn(logits, y_train_tensor)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea63c4",
   "metadata": {},
   "source": [
    "Finally, we print out the metrics of the model and we see that our accuracy (56%) isn't great, but still relatively good for a baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a58bfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5637392751952874\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  White Wins       0.56      0.72      0.63     97110\n",
      "  Black Wins       0.58      0.44      0.50     90637\n",
      "       Draws       0.00      0.00      0.00      7478\n",
      "\n",
      "    accuracy                           0.56    195225\n",
      "   macro avg       0.38      0.39      0.38    195225\n",
      "weighted avg       0.54      0.56      0.54    195225\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\ANACONDA\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "g:\\ANACONDA\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "g:\\ANACONDA\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_test_tensor)\n",
    "    preds = torch.argmax(logits, dim=1).numpy()\n",
    "\n",
    "# Classification report with label names\n",
    "target_names = ['White Wins', 'Black Wins', 'Draws']\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da28bed",
   "metadata": {},
   "source": [
    "## Getting a Baseline\n",
    "   In order to determine a baseline for our chess predictor model we first have to define some prediction objectives. For instance we have to figure out the game outcome (win/loss/draw).\n",
    "   What is the next best move, move classification such as blunder, mistake, good, and excellent.So, first what we will do is look at the features of the data and select only the material_balance, and the result_class. This is so we can predict who will win based on the material balance of the chess pieces on the board as well as getting the result of the match to compare the model to.\n",
    "\n",
    "\n",
    "## Making the Model\n",
    "   After we see what kind of data we're using we then filter out the data that we actually need which is material_balance and result_class. I decided to use a MLP because we're only dealing with a singular, simple numeric feature. Where as if I was creating a model based on all  of the features of the data then I might go with something like a CNN or a RNN because of the spatial data and the sequential data that the dataset provides. Furthermore, I standardize the features of the material_balance mainly because it allows for more stable training which is essential for getting accurate results. I also defined the MLP and used forward pass for the input. We only have 3 output layers which correspond with results of the chess match \"White wins, Black wins, or Draw\"\n",
    "\n",
    "\n",
    "\n",
    "## Selecting Model Features\n",
    "   I also chose 32, and 16 mainly because it gave me the most balance when creating the MLP, of course I could change it to find the best hyperparameters. But for creating a baseline I figured that a simple model would work best in this situation. I also chose 50 epochs here because we aren't trying to get the best accuracy or loss here yet. That's for later on, but 50 epochs is a good baseline to start off with to see how well our model performs. The loss isn't that great for the model, but it is decreasing slowly which means that if we train for more epochs we should be able to get an accurate model.Or by introducing more features or better balance we should be able to create a model that accurately predicts a chess game in the first 15 moves.\n",
    "\n",
    "Finally, we print out the metrics of the model and we see that our accuracy (56%) isn't great, but still relatively good for a baseline model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
